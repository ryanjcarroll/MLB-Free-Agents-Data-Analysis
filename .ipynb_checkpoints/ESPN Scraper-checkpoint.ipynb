{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import bs4\n",
    "from datetime import date\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping From ESPN.com\n",
    "\n",
    "The data we need is located on the ESPN website, but since there is no way to export this data we will use web scraping to compile it into a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of which pages to scrape\n",
    "min_year = 2006\n",
    "max_year = 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(name, year, url, pos, age, status, prev_team, new_team, years_signed, dollars):\n",
    "    with open('players.json') as in_file:\n",
    "        data = json.load(in_file)\n",
    "        \n",
    "        already_exists = False\n",
    "        for player in data:\n",
    "            if player['url'] == url and player['year'] == year:\n",
    "                already_exists = True\n",
    "        \n",
    "        if not already_exists:\n",
    "            new_player = {}\n",
    "            new_player['name'] = name\n",
    "            new_player['year'] = year\n",
    "            new_player['url'] = url\n",
    "            new_player['pos'] = pos\n",
    "            new_player['age'] = age\n",
    "            new_player['status'] = status\n",
    "            new_player['prev_team'] = prev_team\n",
    "            new_player['new_team'] = new_team\n",
    "            new_player['years_signed'] = years_signed\n",
    "            new_player['dollars'] = dollars\n",
    "            \n",
    "            data.append(new_player)\n",
    "            \n",
    "            with open('players.json', 'w') as out_file:\n",
    "                json.dump(data, out_file, indent=4)\n",
    "                \n",
    "            print(\"Saved: {}\". format(name))\n",
    "        else:\n",
    "            print(\"Already Exists: {} \".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARSING YEAR 2006\n",
      "Connection Status Code: 200\n",
      "Already Exists: Matt Albers \n",
      "Already Exists: Sandy Alomar Jr. \n",
      "Already Exists: Moises Alou \n",
      "Already Exists: Rick Ankiel \n",
      "Already Exists: Tony Armas \n"
     ]
    }
   ],
   "source": [
    "for year in range(min_year, max_year + 1):\n",
    "    print(\"PARSING YEAR\", year)\n",
    "    # Send a request to the ESPN page containing the data we need\n",
    "    response = requests.get('http://www.espn.com/mlb/freeagents/_/year/' + str(year))\n",
    "    content = response.content\n",
    "    print(\"Connection Status Code:\", response.status_code)\n",
    "\n",
    "    # Parse the HTML to find the table cells\n",
    "    parser = bs(content, 'html.parser')\n",
    "    table_rows = parser.find_all('tr', class_=['oddrow', 'evenrow'])[:5]\n",
    "    # Save the data in a JSON file\n",
    "    for row in table_rows:\n",
    "        cells = row.select('td')\n",
    "\n",
    "        name = cells[0].text\n",
    "        year = year\n",
    "        pos = cells[1].text\n",
    "        status = cells[3].text\n",
    "        prev_team = cells[4].text\n",
    "        new_team = cells[5].text\n",
    "        years_signed = cells[6].text\n",
    "        dollars = cells[8].text\n",
    "        \n",
    "        # some players have no urls, so we will just skip them\n",
    "        try:\n",
    "            url = cells[0].select('a')[0]['href']\n",
    "        except IndexError:\n",
    "            continue\n",
    "            \n",
    "        # if a player has no age listed, we will also skip them\n",
    "        try:\n",
    "            age = int(cells[2].text) - (date.today().year - year)\n",
    "        except ValueError:\n",
    "            continue        \n",
    "\n",
    "        save_to_json(name, year, url, pos, age, status, prev_team, new_team, years_signed, dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

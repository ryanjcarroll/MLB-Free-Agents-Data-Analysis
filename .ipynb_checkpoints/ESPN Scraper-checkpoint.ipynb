{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import bs4\n",
    "from datetime import date\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping From ESPN.com\n",
    "\n",
    "The data we need is located on the ESPN website, but since there is no way to export this data we will use web scraping to compile it into a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of which pages to scrape\n",
    "min_year = 2006\n",
    "max_year = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes a player's scraped data and appends it to a JSON file containing all data.  For statistical data, we create one file for batters, and one for pitchers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(name, year, url, pos, age, status, prev_team, new_team, years_signed, dollars, stat_names, stats):\n",
    "    # load the correct JSON based on pitcher/batter position\n",
    "    if pos == 'SP' or pos =='RP' or pos =='P':\n",
    "        file_path = 'pitchers_stats.json'\n",
    "    else:\n",
    "        file_path = 'batters_stats.json'\n",
    "        \n",
    "    with open(file_path) as in_file:\n",
    "        data = json.load(in_file)\n",
    "        \n",
    "    # check to make sure player/year combo is not already added\n",
    "    already_exists = False\n",
    "    for player in data:\n",
    "        if player['url'] == url and player['year'] == year:\n",
    "            already_exists = True\n",
    "    \n",
    "    if not already_exists:\n",
    "        new_player = {}\n",
    "\n",
    "        # add general player and contract info\n",
    "        new_player['name'] = name\n",
    "        new_player['year'] = year\n",
    "        new_player['url'] = url\n",
    "        new_player['pos'] = pos\n",
    "        new_player['age'] = age\n",
    "        new_player['status'] = status\n",
    "        new_player['prev_team'] = prev_team\n",
    "        new_player['new_team'] = new_team\n",
    "        new_player['years_signed'] = years_signed\n",
    "        new_player['dollars'] = dollars\n",
    "\n",
    "        # add player's stats over the previous 3 years\n",
    "        for year in range(0, len(stats)):\n",
    "            year_list = {}\n",
    "            for i in range(len(stat_names)):\n",
    "                year_list[stat_names[i]] = stats[year][i]\n",
    "            new_player['stats_' + str(year+1) + 'yr_ago'] = year_list\n",
    "            \n",
    "        data.append(new_player)\n",
    "\n",
    "        # write new data to the JSON\n",
    "        with open(file_path, 'w') as out_file:\n",
    "            json.dump(data, out_file, indent=4)\n",
    "\n",
    "        print(\"Saved: {}\". format(name))\n",
    "    else:\n",
    "        print(\"Already Exists: {} \".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is called to find a list of stats for a given player.  Inputs are a list of years to find stats from, and a list of stats to look for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return format will be a list of yearly data lists\n",
    "# ex. years = [2015,2016], stat_names = [AB, WAR]\n",
    "# stats = [[480,3.1],[355, 2.5]]\n",
    "def find_stats(url, years, stat_names):\n",
    "    stats = []\n",
    "    # send a request to the ESPN stats page for a player\n",
    "    url_split = url.split('player/')\n",
    "    url = url_split[0] + 'player/stats/' + url_split[1]\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "    \n",
    "    # parse the HTML to find the relevant table of statistics\n",
    "    parser = bs(content, 'html.parser')\n",
    "    table = parser.find('section', class_='ResponsiveTable')\n",
    "    \n",
    "    # find the row number(s) in the table corresponding to the relevant year(s)\n",
    "    row_nums = []\n",
    "    table_left = table.find('table', class_='Table--fixed-left').find('tbody')\n",
    "    row_years = table_left.findAll('tr')\n",
    "    for year in years:\n",
    "        row_list = []\n",
    "        for row in row_years:\n",
    "            cell = row.find('td')\n",
    "            if cell.text == str(year):\n",
    "                row_list.append(row['data-idx'])\n",
    "        row_nums.append(row_list)\n",
    "    \n",
    "    # find the column number(s) in the table corresponding to the relevant statistic(s)\n",
    "    table_body = table.find('div', class_='Table__Scroller')\n",
    "    col_nums = []\n",
    "    columns = table_body.findAll('th')\n",
    "    for stat_name in stat_names:\n",
    "        col_num = 0\n",
    "        for col in columns:\n",
    "            if col.text == stat_name:\n",
    "                col_nums.append(col_num)\n",
    "                break\n",
    "            col_num += 1\n",
    "    \n",
    "    # find the stat data at the calculated row and column of the table\n",
    "    table_data = table_body.find('tbody', class_='Table__TBODY')\n",
    "    for row_list in row_nums:\n",
    "        yearly_stats = []\n",
    "        # if a player did not play in a year\n",
    "        if len(row_list) == 0:\n",
    "            for col_num in col_nums:\n",
    "                yearly_stats.append('None')\n",
    "                \n",
    "        # if player had multiple teams in one year, combine all rows of data into one row\n",
    "        elif len(row_list) > 1:\n",
    "            yearly_stats_by_team = []\n",
    "            for row_list_item in row_list:\n",
    "                team_stats = []\n",
    "                row = table_data.find('tr',class_='Table__TR', attrs={'data-idx':row_list_item})\n",
    "                for col_num in col_nums:\n",
    "                    index = 0\n",
    "                    for cell in row.findAll('td'):\n",
    "                        if index == col_num:\n",
    "                            team_stats.append(cell.text)\n",
    "                        index += 1\n",
    "                yearly_stats_by_team.append(team_stats)\n",
    "            \n",
    "            # sum the counting stats across each team per year\n",
    "            for i in range(len(stat_names)):\n",
    "                total = 0\n",
    "                for team_stats in yearly_stats_by_team:\n",
    "                    if stat_names[i] in ['WAR','IP']:\n",
    "                        total += float(team_stats[i])\n",
    "                    else:\n",
    "                        total += int(team_stats[i])\n",
    "                yearly_stats.append(str(total))\n",
    "            \n",
    "        # if player had exactly one team in a year\n",
    "        else:\n",
    "            row = table_data.find('tr',class_='Table__TR', attrs={'data-idx':row_list[0]})\n",
    "            for col_num in col_nums:\n",
    "                index = 0\n",
    "                for cell in row.findAll('td'):\n",
    "                    if index == col_num:\n",
    "                        yearly_stats.append(cell.text)\n",
    "                    index += 1\n",
    "        stats.append(yearly_stats)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run the actual web scraper, using data from ESPN's MLB Free Agent Tracker and sending requests to their player statistics pages for each player listed on the tracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for year in range(min_year, max_year + 1):\n",
    "    print(\"PARSING YEAR\", year)\n",
    "    # Send a request to the ESPN page containing the data we need\n",
    "    response = requests.get('http://www.espn.com/mlb/freeagents/_/year/' + str(year))\n",
    "    content = response.content\n",
    "    print(\"Connection Status Code:\", response.status_code)\n",
    "\n",
    "    # Parse the HTML to find the table cells\n",
    "    parser = bs(content, 'html.parser')\n",
    "    table_rows = parser.find_all('tr', class_=['oddrow', 'evenrow'])\n",
    "    \n",
    "    # Save the data in a JSON file\n",
    "    for row in table_rows:\n",
    "        cells = row.select('td')\n",
    "\n",
    "        name = cells[0].text\n",
    "        year = year\n",
    "        pos = cells[1].text\n",
    "        status = cells[3].text\n",
    "        prev_team = cells[4].text\n",
    "        new_team = cells[5].text\n",
    "        years_signed = cells[6].text\n",
    "        dollars = cells[8].text\n",
    "                \n",
    "        # some players have no urls, so we will just skip them\n",
    "        try:\n",
    "            url = cells[0].select('a')[0]['href']\n",
    "        except IndexError:\n",
    "            continue\n",
    "            \n",
    "        # if a player has no age listed, we will also skip them\n",
    "        try:\n",
    "            age = int(cells[2].text) - (date.today().year - year)\n",
    "        except ValueError:\n",
    "            continue        \n",
    "            \n",
    "        # also skip players who did not sign a contract during their FA period\n",
    "        if years_signed == '':\n",
    "            continue\n",
    "        elif new_team == '--':\n",
    "            continue\n",
    "        elif dollars == '--' or dollars == 'Minor Lg':\n",
    "            continue\n",
    "            \n",
    "        # skip a  few players whose ESPN profiles are bugged / have no data\n",
    "        if name in ['Jos√© Molina','Brian Anderson','Hiroyuki Nakajima','Yaisel Sierra','Thomas Milone']:\n",
    "            continue\n",
    "        \n",
    "        # given a list of years and stats to find, retrieve the relevant data for that player\n",
    "        years = [year, year-1, year-2]\n",
    "        if pos == 'SP' or pos == 'RP' or pos== 'P':\n",
    "            stat_names = ['GP','GS','W','L','IP','K','BB','H','R','ER','SV','HLD','BLSV','WAR']\n",
    "        else:\n",
    "            stat_names = ['GP','AB','R','H','2B','3B','HR','RBI','BB','HBP','SO','SB','CS','WAR']\n",
    "        \n",
    "        stats = find_stats(url, years, stat_names)\n",
    "        save_to_json(name, year, url, pos, age, status, prev_team, new_team, years_signed, dollars, stat_names, stats)\n",
    "        \n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

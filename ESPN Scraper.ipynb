{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import bs4\n",
    "from datetime import date\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "\n",
    "Scraper does not account for trade years, only counts stats from the lastinstance of a year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping From ESPN.com\n",
    "\n",
    "The data we need is located on the ESPN website, but since there is no way to export this data we will use web scraping to compile it into a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of which pages to scrape\n",
    "min_year = 2016\n",
    "max_year = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes a player's scraped data and appends it to a JSON file containing all data.  For statistical data, we create one file for batters, and one for pitchers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(name, year, url, pos, age, status, prev_team, new_team, years_signed, dollars, stat_names, stats):\n",
    "    # load the correct JSON based on pitcher/batter position\n",
    "    if pos == 'SP' or pos =='RP' or pos =='P':\n",
    "        file_path = 'pitchers_stats.json'\n",
    "    else:\n",
    "        file_path = 'batters_stats.json'\n",
    "        \n",
    "    with open(file_path) as in_file:\n",
    "        data = json.load(in_file)\n",
    "        \n",
    "    # check to make sure player/year combo is not already added\n",
    "    already_exists = False\n",
    "    for player in data:\n",
    "        if player['url'] == url and player['year'] == year:\n",
    "            already_exists = True\n",
    "    \n",
    "    if not already_exists:\n",
    "        new_player = {}\n",
    "\n",
    "        # add general player and contract info\n",
    "        new_player['name'] = name\n",
    "        new_player['year'] = year\n",
    "        new_player['url'] = url\n",
    "        new_player['pos'] = pos\n",
    "        new_player['age'] = age\n",
    "        new_player['status'] = status\n",
    "        new_player['prev_team'] = prev_team\n",
    "        new_player['new_team'] = new_team\n",
    "        new_player['years_signed'] = years_signed\n",
    "        new_player['dollars'] = dollars\n",
    "\n",
    "        # add player's stats over the previous 3 years\n",
    "        for year in range(0, len(stats)):\n",
    "            year_list = {}\n",
    "            for i in range(len(stat_names)):\n",
    "                year_list[stat_names[i]] = stats[year][i]\n",
    "            new_player['stats_' + str(year+1) + 'yr_ago'] = year_list\n",
    "            \n",
    "        data.append(new_player)\n",
    "\n",
    "        # write new data to the JSON\n",
    "        with open(file_path, 'w') as out_file:\n",
    "            json.dump(data, out_file, indent=4)\n",
    "\n",
    "        print(\"Saved: {}\". format(name))\n",
    "    else:\n",
    "        print(\"Already Exists: {} \".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is called to find a list of stats for a given player.  Inputs are a list of years to find stats from, and a list of stats to look for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return format will be a list of yearly data lists\n",
    "# ex. years = [2015,2016], stat_names = [AB, WAR]\n",
    "# stats = [[480,3.1],[355, 2.5]]\n",
    "def find_stats(url, years, stat_names):\n",
    "    stats = []\n",
    "    # send a request to the ESPN stats page for a player\n",
    "    url_split = url.split('player/')\n",
    "    url = url_split[0] + 'player/stats/' + url_split[1]\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "    \n",
    "    # parse the HTML to find the relevant table of statistics\n",
    "    parser = bs(content, 'html.parser')\n",
    "    table = parser.find('section', class_='ResponsiveTable')\n",
    "    \n",
    "    # find the row number(s) in the table corresponding to the relevant year(s)\n",
    "    row_nums = []\n",
    "    table_left = table.find('table', class_='Table--fixed-left').find('tbody')\n",
    "    row_years = table_left.findAll('tr')\n",
    "    for year in years:\n",
    "        row_list = []\n",
    "        for row in row_years:\n",
    "            cell = row.find('td')\n",
    "            if cell.text == str(year):\n",
    "                row_list.append(row['data-idx'])\n",
    "        row_nums.append(row_list)\n",
    "    \n",
    "    # find the column number(s) in the table corresponding to the relevant statistic(s)\n",
    "    table_body = table.find('div', class_='Table__Scroller')\n",
    "    col_nums = []\n",
    "    columns = table_body.findAll('th')\n",
    "    for stat_name in stat_names:\n",
    "        col_num = 0\n",
    "        for col in columns:\n",
    "            if col.text == stat_name:\n",
    "                col_nums.append(col_num)\n",
    "                break\n",
    "            col_num += 1\n",
    "    \n",
    "    # find the stat data at the calculated row and column of the table\n",
    "    table_data = table_body.find('tbody', class_='Table__TBODY')\n",
    "    for row_list in row_nums:\n",
    "        yearly_stats = []\n",
    "        # if a player did not play in a year\n",
    "        if len(row_list) == 0:\n",
    "            for col_num in col_nums:\n",
    "                yearly_stats.append('None')\n",
    "                \n",
    "        # if player had multiple teams in one year, combine all rows of data into one row\n",
    "        elif len(row_list) > 1:\n",
    "            yearly_stats_by_team = []\n",
    "            for row_list_item in row_list:\n",
    "                team_stats = []\n",
    "                row = table_data.find('tr',class_='Table__TR', attrs={'data-idx':row_list_item})\n",
    "                for col_num in col_nums:\n",
    "                    index = 0\n",
    "                    for cell in row.findAll('td'):\n",
    "                        if index == col_num:\n",
    "                            team_stats.append(cell.text)\n",
    "                        index += 1\n",
    "                yearly_stats_by_team.append(team_stats)\n",
    "            \n",
    "            # sum the counting stats across each team per year\n",
    "            for i in range(len(stat_names)):\n",
    "                total = 0\n",
    "                for team_stats in yearly_stats_by_team:\n",
    "                    if stat_names[i] in ['WAR','IP']:\n",
    "                        total += float(team_stats[i])\n",
    "                    else:\n",
    "                        total += int(team_stats[i])\n",
    "                yearly_stats.append(str(total))\n",
    "            \n",
    "        # if player had exactly one team in a year\n",
    "        else:\n",
    "            row = table_data.find('tr',class_='Table__TR', attrs={'data-idx':row_list[0]})\n",
    "            for col_num in col_nums:\n",
    "                index = 0\n",
    "                for cell in row.findAll('td'):\n",
    "                    if index == col_num:\n",
    "                        yearly_stats.append(cell.text)\n",
    "                    index += 1\n",
    "        stats.append(yearly_stats)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run the actual web scraper, using data from ESPN's MLB Free Agent Tracker and sending requests to their player statistics pages for each player listed on the tracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARSING YEAR 2016\n",
      "Connection Status Code: 200\n",
      "Saved: Mike Napoli\n",
      "Saved: Ivan Nova\n",
      "Saved: Logan Ondrusek\n",
      "Saved: Steve Pearce\n",
      "Saved: Trevor Plouffe\n",
      "Saved: Wilson Ramos\n",
      "Saved: Colby Rasmus\n",
      "Saved: Josh Reddick\n",
      "Saved: Ben Revere\n",
      "Saved: Clayton Richard\n",
      "Saved: Fernando Rodney\n",
      "Saved: Sean Rodriguez\n",
      "Saved: Sergio Romo\n",
      "Saved: Adam Rosales\n",
      "Saved: Tyson Ross\n",
      "Saved: Marc Rzepczynski\n",
      "Saved: Fernando Salas\n",
      "Saved: Michael Saunders\n",
      "Saved: Joe Smith\n",
      "Saved: Drew Storen\n",
      "Saved: Kurt Suzuki\n",
      "Saved: Junichi Tazawa\n",
      "Saved: Eric Thames\n",
      "Saved: Shawn Tolleson\n",
      "Saved: Mark Trumbo\n",
      "Saved: Justin Turner\n",
      "Saved: Koji Uehara\n",
      "Saved: Chase Utley\n",
      "Saved: Luis Valbuena\n",
      "Saved: Edinson Volquez\n",
      "Saved: Neil Walker\n",
      "Saved: Jered Weaver\n",
      "Saved: Matt Wieters\n",
      "Saved: Travis Wood\n",
      "Saved: Brad Ziegler\n",
      "PARSING YEAR 2017\n",
      "Connection Status Code: 200\n",
      "Saved: Logan Morrison\n",
      "Saved: Brandon Morrow\n",
      "Saved: Mike Moustakas\n",
      "Saved: Pat Neshek\n",
      "Saved: Juan Nicasio\n",
      "Saved: Bud Norris\n",
      "Saved: Eduardo Nunez\n",
      "Saved: Seunghwan Oh\n",
      "Saved: Wily Peralta\n",
      "Saved: Yusmeiro Petit\n",
      "Saved: Michael Pineda\n",
      "Saved: Addison Reed\n",
      "Saved: Jose Reyes\n",
      "Saved: Rene Rivera\n",
      "Saved: Fernando Rodney\n",
      "Saved: Sergio Romo\n",
      "Saved: Hector Rondon\n",
      "Saved: CC Sabathia\n",
      "Saved: Anibal Sanchez\n",
      "Saved: Carlos Santana\n",
      "Saved: Bryan Shaw\n",
      "Saved: Joe Smith\n",
      "Saved: Drew Smyly\n",
      "Saved: Craig Stammen\n",
      "Saved: Anthony Swarzak\n",
      "Saved: Chris Tillman\n",
      "Saved: Chase Utley\n",
      "Saved: Jason Vargas\n",
      "Saved: Neil Walker\n",
      "Saved: Tony Watson\n",
      "Saved: Chris Young\n",
      "PARSING YEAR 2018\n",
      "Connection Status Code: 200\n",
      "Saved: Shawn Kelley\n",
      "Saved: Joe Kelly\n",
      "Saved: Yusei Kikuchi\n",
      "Saved: Ian Kinsler\n",
      "Saved: DJ LeMahieu\n",
      "Saved: Aaron Loup\n",
      "Saved: Jed Lowrie\n",
      "Saved: Jonathan Lucroy\n",
      "Saved: Jordan Lyles\n",
      "Saved: Lance Lynn\n",
      "Saved: Manny Machado\n",
      "Saved: Martin Maldonado\n",
      "Saved: Nick Markakis\n",
      "Saved: Jeff Mathis\n",
      "Saved: Brian McCann\n",
      "Saved: James McCann\n",
      "Saved: Andrew McCutchen\n",
      "Saved: Jordy Mercer\n",
      "Saved: Wade Miley\n",
      "Saved: Andrew Miller\n",
      "Saved: Shelby Miller\n",
      "Saved: Matt Moore\n",
      "Saved: Charlie Morton\n",
      "Saved: Mike Moustakas\n",
      "Saved: Daniel Murphy\n",
      "Saved: Adam Ottavino\n",
      "Saved: Chris Owings\n",
      "Saved: Blake Parker\n",
      "Saved: Steve Pearce\n",
      "Saved: Martin Perez\n",
      "Saved: Oliver Perez\n",
      "Saved: David Phelps\n",
      "Saved: A.J. Pollock\n",
      "Saved: Drew Pomeranz\n",
      "Saved: Wilson Ramos\n",
      "Saved: Garrett Richards\n",
      "Saved: David Robertson\n",
      "Saved: Sergio Romo\n",
      "Saved: Trevor Rosenthal\n",
      "Saved: Tyson Ross\n",
      "Saved: Hyun-Jin Ryu\n",
      "Saved: CC Sabathia\n",
      "Saved: Anibal Sanchez\n",
      "Saved: Jonathan Schoop\n",
      "Saved: Matt Shoemaker\n",
      "Saved: Tony Sipp\n",
      "Saved: Joakim Soria\n",
      "Saved: Hunter Strickland\n",
      "Saved: Jesus Sucre\n",
      "Saved: Kurt Suzuki\n",
      "Saved: Ronald Torreyes\n",
      "Saved: Troy Tulowitzki\n",
      "Saved: Pat Venditte\n",
      "Saved: Neil Walker\n",
      "Saved: Adam Warren\n",
      "Saved: Justin Wilson\n",
      "PARSING YEAR 2019\n",
      "Connection Status Code: 200\n",
      "Saved: Jeremy Jeffress\n",
      "Saved: Matt Joyce\n",
      "Saved: Howie Kendrick\n",
      "Saved: Dallas Keuchel\n",
      "Saved: Brandon Kintzler\n",
      "Saved: Jason Kipnis\n",
      "Saved: Josh Lindblom\n",
      "Saved: Jordan Lyles\n",
      "Saved: Luke Maile\n",
      "Saved: Martin Maldonado\n",
      "Saved: Cameron Maybin\n",
      "Saved: T.J. McFarland\n",
      "Saved: Wade Miley\n",
      "Saved: Brad Miller\n",
      "Saved: Mitch Moreland\n",
      "Saved: Mike Moustakas\n",
      "Saved: Ivan Nova\n",
      "Saved: Darren O'Day\n",
      "Saved: Jake Odorizzi\n",
      "Saved: Josh Osich\n",
      "Saved: Marcell Ozuna\n",
      "Saved: Hunter Pence\n",
      "Saved: Jose Peraza\n",
      "Saved: Hernan Perez\n",
      "Saved: Martin Perez\n",
      "Saved: Kevin Pillar\n",
      "Saved: Michael Pineda\n",
      "Saved: Kevin Plawecki\n",
      "Saved: Drew Pomeranz\n",
      "Saved: Rick Porcello\n",
      "Saved: Anthony Rendon\n",
      "Saved: JT Riddle\n",
      "Saved: Tanner Roark\n",
      "Saved: Austin Romine\n",
      "Saved: Sergio Romo\n",
      "Saved: Hector Rondon\n",
      "Saved: Hyun-Jin Ryu\n",
      "Saved: Domingo Santana\n",
      "Saved: Jonathan Schoop\n",
      "Saved: Travis Shaw\n",
      "Saved: Joe Smith\n",
      "Saved: Will Smith\n",
      "Saved: Justin Smoak\n",
      "Saved: Drew Smyly\n",
      "Saved: Eric Sogard\n",
      "Saved: Steven Souza Jr.\n",
      "Saved: Craig Stammen\n",
      "Saved: Stephen Strasburg\n",
      "Saved: Pedro Strop\n",
      "Saved: Julio Teheran\n",
      "Saved: Eric Thames\n",
      "Saved: Blake Treinen\n",
      "Saved: Stephen Vogt\n",
      "Saved: Michael Wacha\n",
      "Saved: Adam Wainwright\n",
      "Saved: Taijuan Walker\n",
      "Saved: Zack Wheeler\n",
      "Saved: Matt Wieters\n",
      "Saved: Alex Wood\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "for year in range(min_year, max_year + 1):\n",
    "    print(\"PARSING YEAR\", year)\n",
    "    # Send a request to the ESPN page containing the data we need\n",
    "    response = requests.get('http://www.espn.com/mlb/freeagents/_/year/' + str(year))\n",
    "    content = response.content\n",
    "    print(\"Connection Status Code:\", response.status_code)\n",
    "\n",
    "    # Parse the HTML to find the table cells\n",
    "    parser = bs(content, 'html.parser')\n",
    "    table_rows = parser.find_all('tr', class_=['oddrow', 'evenrow'])\n",
    "    # Save the data in a JSON file\n",
    "    for row in table_rows[130:]:\n",
    "        cells = row.select('td')\n",
    "\n",
    "        name = cells[0].text\n",
    "        year = year\n",
    "        pos = cells[1].text\n",
    "        status = cells[3].text\n",
    "        prev_team = cells[4].text\n",
    "        new_team = cells[5].text\n",
    "        years_signed = cells[6].text\n",
    "        dollars = cells[8].text\n",
    "                \n",
    "        # some players have no urls, so we will just skip them\n",
    "        try:\n",
    "            url = cells[0].select('a')[0]['href']\n",
    "        except IndexError:\n",
    "            continue\n",
    "            \n",
    "        # if a player has no age listed, we will also skip them\n",
    "        try:\n",
    "            age = int(cells[2].text) - (date.today().year - year)\n",
    "        except ValueError:\n",
    "            continue        \n",
    "            \n",
    "        # also skip players who did not sign a contract during their FA period\n",
    "        if years_signed == '':\n",
    "            continue\n",
    "        elif new_team == '--':\n",
    "            continue\n",
    "        elif dollars == '--' or dollars == 'Minor Lg':\n",
    "            continue\n",
    "            \n",
    "        # skip a  few players whose ESPN profiles are bugged / have no data\n",
    "        if name in ['José Molina','Brian Anderson','Hiroyuki Nakajima','Yaisel Sierra']:\n",
    "            continue\n",
    "        \n",
    "        # given a list of years and stats to find, retrieve the relevant data for that player\n",
    "        years = [year, year-1, year-2]\n",
    "        if pos == 'SP' or pos == 'RP' or pos== 'P':\n",
    "            stat_names = ['GP','GS','W','L','IP','K','BB','H','R','ER','SV','HLD','BLSV','WAR']\n",
    "        else:\n",
    "            stat_names = ['GP','AB','R','H','2B','3B','HR','RBI','BB','HBP','SO','SB','CS','WAR']\n",
    "        \n",
    "        stats = find_stats(url, years, stat_names)\n",
    "        save_to_json(name, year, url, pos, age, status, prev_team, new_team, years_signed, dollars, stat_names, stats)\n",
    "        \n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

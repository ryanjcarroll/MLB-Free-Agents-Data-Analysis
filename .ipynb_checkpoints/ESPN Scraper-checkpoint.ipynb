{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import bs4\n",
    "from datetime import date\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "\n",
    "Scraper does not account for trade years, only counts stats from the lastinstance of a year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping From ESPN.com\n",
    "\n",
    "The data we need is located on the ESPN website, but since there is no way to export this data we will use web scraping to compile it into a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of which pages to scrape\n",
    "min_year = 2017\n",
    "max_year = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes a player's scraped data and appends it to a JSON file containing all data.  For statistical data, we create one file for batters, and one for pitchers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(name, year, url, pos, age, status, prev_team, new_team, years_signed, dollars, stat_names, stats):\n",
    "    # load the correct JSON based on pitcher/batter position\n",
    "    if pos == 'SP' or pos =='RP' or pos =='P':\n",
    "        file_path = 'pitchers_stats.json'\n",
    "    else:\n",
    "        file_path = 'batters_stats.json'\n",
    "        \n",
    "    with open(file_path) as in_file:\n",
    "        data = json.load(in_file)\n",
    "        \n",
    "    # check to make sure player/year combo is not already added\n",
    "    already_exists = False\n",
    "    for player in data:\n",
    "        if player['url'] == url and player['year'] == year:\n",
    "            already_exists = True\n",
    "    \n",
    "    if not already_exists:\n",
    "        new_player = {}\n",
    "\n",
    "        # add general player and contract info\n",
    "        new_player['name'] = name\n",
    "        new_player['year'] = year\n",
    "        new_player['url'] = url\n",
    "        new_player['pos'] = pos\n",
    "        new_player['age'] = age\n",
    "        new_player['status'] = status\n",
    "        new_player['prev_team'] = prev_team\n",
    "        new_player['new_team'] = new_team\n",
    "        new_player['years_signed'] = years_signed\n",
    "        new_player['dollars'] = dollars\n",
    "\n",
    "        # add player's stats over the previous 3 years\n",
    "        for year in range(0, len(stats)):\n",
    "            year_list = {}\n",
    "            for i in range(len(stat_names)):\n",
    "                year_list[stat_names[i]] = stats[year][i]\n",
    "            new_player['stats_' + str(year+1) + 'yr_ago'] = year_list\n",
    "            \n",
    "        data.append(new_player)\n",
    "\n",
    "        # write new data to the JSON\n",
    "        with open(file_path, 'w') as out_file:\n",
    "            json.dump(data, out_file, indent=4)\n",
    "\n",
    "        print(\"Saved: {}\". format(name))\n",
    "    else:\n",
    "        print(\"Already Exists: {} \".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is called to find a list of stats for a given player.  Inputs are a list of years to find stats from, and a list of stats to look for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return format will be a list of yearly data lists\n",
    "# ex. years = [2015,2016], stat_names = [AB, WAR]\n",
    "# stats = [[480,3.1],[355, 2.5]]\n",
    "def find_stats(url, years, stat_names):\n",
    "    stats = []\n",
    "    # send a request to the ESPN stats page for a player\n",
    "    url_split = url.split('player/')\n",
    "    url = url_split[0] + 'player/stats/' + url_split[1]\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "    \n",
    "    # parse the HTML to find the relevant table of statistics\n",
    "    parser = bs(content, 'html.parser')\n",
    "    table = parser.find('section', class_='ResponsiveTable')\n",
    "    \n",
    "    # find the row number(s) in the table corresponding to the relevant year(s)\n",
    "    row_nums = []\n",
    "    table_left = table.find('table', class_='Table--fixed-left').find('tbody')\n",
    "    row_years = table_left.findAll('tr')\n",
    "    for year in years:\n",
    "        row_list = []\n",
    "        for row in row_years:\n",
    "            cell = row.find('td')\n",
    "            if cell.text == str(year):\n",
    "                row_list.append(row['data-idx'])\n",
    "        row_nums.append(row_list)\n",
    "    \n",
    "    # find the column number(s) in the table corresponding to the relevant statistic(s)\n",
    "    table_body = table.find('div', class_='Table__Scroller')\n",
    "    col_nums = []\n",
    "    columns = table_body.findAll('th')\n",
    "    for stat_name in stat_names:\n",
    "        col_num = 0\n",
    "        for col in columns:\n",
    "            if col.text == stat_name:\n",
    "                col_nums.append(col_num)\n",
    "                break\n",
    "            col_num += 1\n",
    "    \n",
    "    # find the stat data at the calculated row and column of the table\n",
    "    table_data = table_body.find('tbody', class_='Table__TBODY')\n",
    "    for row_list in row_nums:\n",
    "        yearly_stats = []\n",
    "        # if a player did not play in a year\n",
    "        if len(row_list) == 0:\n",
    "            for col_num in col_nums:\n",
    "                yearly_stats.append('None')\n",
    "                \n",
    "        # if player had multiple teams in one year, combine all rows of data into one row\n",
    "        elif len(row_list) > 1:\n",
    "            yearly_stats_by_team = []\n",
    "            for row_list_item in row_list:\n",
    "                team_stats = []\n",
    "                row = table_data.find('tr',class_='Table__TR', attrs={'data-idx':row_list_item})\n",
    "                for col_num in col_nums:\n",
    "                    index = 0\n",
    "                    for cell in row.findAll('td'):\n",
    "                        if index == col_num:\n",
    "                            team_stats.append(cell.text)\n",
    "                        index += 1\n",
    "                yearly_stats_by_team.append(team_stats)\n",
    "            \n",
    "            # sum the counting stats across each team per year\n",
    "            for i in range(len(stat_names)):\n",
    "                total = 0\n",
    "                for team_stats in yearly_stats_by_team:\n",
    "                    if stat_names[i] in ['WAR','IP']:\n",
    "                        total += float(team_stats[i])\n",
    "                    else:\n",
    "                        total += int(team_stats[i])\n",
    "                yearly_stats.append(str(total))\n",
    "            \n",
    "        # if player had exactly one team in a year\n",
    "        else:\n",
    "            row = table_data.find('tr',class_='Table__TR', attrs={'data-idx':row_list[0]})\n",
    "            for col_num in col_nums:\n",
    "                index = 0\n",
    "                for cell in row.findAll('td'):\n",
    "                    if index == col_num:\n",
    "                        yearly_stats.append(cell.text)\n",
    "                    index += 1\n",
    "        stats.append(yearly_stats)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run the actual web scraper, using data from ESPN's MLB Free Agent Tracker and sending requests to their player statistics pages for each player listed on the tracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARSING YEAR 2017\n",
      "Connection Status Code: 200\n",
      "Saved: Matt Adams\n",
      "Saved: Matt Albers\n",
      "Saved: Yonder Alonso\n",
      "Saved: Jake Arrieta\n",
      "Saved: Alex Avila\n",
      "Saved: Erick Aybar\n",
      "Saved: Tony Barnette\n",
      "Saved: Joaquin Benoit\n",
      "Saved: Peter Bourjos\n",
      "Saved: Jay Bruce\n",
      "Saved: Trevor Cahill\n",
      "Saved: Lorenzo Cain\n",
      "Saved: Andrew Cashner\n",
      "Saved: Welington Castillo\n",
      "Saved: Jhoulys Chacin\n",
      "Saved: Tyler Chatwood\n",
      "Saved: Jesse Chavez\n",
      "Saved: Steve Cishek\n",
      "Saved: Alex Cobb\n",
      "Saved: Zack Cozart\n",
      "Saved: Yu Darvish\n",
      "Saved: Wade Davis\n",
      "Saved: Lucas Duda\n",
      "Saved: Brian Duensing\n",
      "Saved: Zach Duke\n",
      "Saved: Jarrod Dyson\n",
      "Saved: Alcides Escobar\n",
      "Saved: Mike Fiers\n",
      "Saved: Doug Fister\n",
      "Saved: Todd Frazier\n",
      "Saved: Yovani Gallardo\n",
      "Saved: Jaime Garcia\n",
      "Saved: Carlos Gomez\n",
      "Saved: Carlos Gonzalez\n",
      "Saved: Miguel Gonzalez\n",
      "Saved: Curtis Granderson\n",
      "Saved: Luke Gregerson\n",
      "Saved: David Hernandez\n",
      "Saved: Eric Hosmer\n",
      "Saved: Jared Hughes\n",
      "Saved: Nick Hundley\n",
      "Saved: Tommy Hunter\n",
      "Saved: Chris Iannetta\n",
      "Saved: Austin Jackson\n",
      "Saved: Howie Kendrick\n",
      "Saved: Brandon Kintzler\n",
      "Saved: Tom Koehler\n",
      "Saved: Francisco Liriano\n",
      "Saved: Boone Logan\n",
      "Saved: Jonathan Lucroy\n",
      "Saved: Jordan Lyles\n",
      "Saved: Lance Lynn\n",
      "Saved: Leonys Martin\n",
      "Already Exists: J.D. Martinez \n",
      "Saved: Cameron Maybin\n",
      "Saved: T.J. McFarland\n",
      "Saved: Jake McGee\n",
      "Saved: Mike Minor\n",
      "Saved: Mitch Moreland\n",
      "Already Exists: Logan Morrison \n",
      "Already Exists: Brandon Morrow \n",
      "Already Exists: Mike Moustakas \n",
      "Already Exists: Pat Neshek \n",
      "Already Exists: Juan Nicasio \n",
      "PARSING YEAR 2018\n",
      "Connection Status Code: 200\n",
      "Saved: Matt Adams\n",
      "Saved: Cody Allen\n",
      "Saved: Brett Anderson\n",
      "Saved: Tony Barnette\n",
      "Saved: Tim Beckham\n",
      "Saved: Justin Bour\n",
      "Saved: Brad Boxberger\n",
      "Saved: Brad Brach\n",
      "Saved: Michael Brantley\n",
      "Saved: Zack Britton\n",
      "Saved: Clay Buchholz\n",
      "Saved: Asdrubal Cabrera\n",
      "Saved: Trevor Cahill\n",
      "Saved: Xavier Cedeno\n",
      "Saved: Jesse Chavez\n",
      "Saved: Robinson Chirinos\n",
      "Saved: Lonnie Chisenhall\n",
      "Saved: Patrick Corbin\n",
      "Saved: Nelson Cruz\n",
      "Saved: Daniel Descalso\n",
      "Saved: Jake Diekman\n",
      "Saved: Josh Donaldson\n",
      "Saved: Brian Dozier\n",
      "Saved: Zach Duke\n",
      "Saved: Nathan Eovaldi\n",
      "Saved: Eduardo Escobar\n",
      "Saved: Marco Estrada\n",
      "Saved: Jeurys Familia\n",
      "Saved: Mike Fiers\n",
      "Saved: Wilmer Flores\n",
      "Saved: David Freese\n",
      "Saved: Freddy Galvis\n",
      "Saved: Avisail Garcia\n",
      "Saved: Brett Gardner\n",
      "Saved: Cory Gearrin\n",
      "Saved: Marwin Gonzalez\n",
      "Saved: Terrance Gore\n",
      "Saved: Yasmani Grandal\n",
      "Saved: Robbie Grossman\n",
      "Saved: Billy Hamilton\n",
      "Saved: J.A. Happ\n",
      "Saved: Bryce Harper\n",
      "Saved: Matt Harvey\n",
      "Saved: Jeremy Hellickson\n",
      "Saved: Kelvin Herrera\n",
      "Saved: Chris Herrmann\n",
      "Saved: Derek Holland\n",
      "Saved: Greg Holland\n",
      "Saved: Jon Jay\n",
      "Saved: Adam Jones\n",
      "Saved: Caleb Joseph\n",
      "Saved: Jung Ho Kang\n",
      "Saved: Nate Karns\n",
      "Already Exists: Shawn Kelley \n",
      "Already Exists: Joe Kelly \n",
      "Already Exists: Yusei Kikuchi \n",
      "Already Exists: Ian Kinsler \n",
      "Already Exists: DJ LeMahieu \n",
      "PARSING YEAR 2019\n",
      "Connection Status Code: 200\n",
      "Saved: Jose Abreu\n",
      "Saved: Brett Anderson\n",
      "Saved: Tyler Anderson\n",
      "Saved: Alex Avila\n",
      "Saved: Homer Bailey\n",
      "Saved: Dellin Betances\n",
      "Saved: Brad Brach\n",
      "Saved: Madison Bumgarner\n",
      "Saved: Asdrubal Cabrera\n",
      "Saved: Kole Calhoun\n",
      "Saved: Nicholas Castellanos\n",
      "Saved: Jason Castro\n",
      "Saved: Starlin Castro\n",
      "Saved: Francisco Cervelli\n",
      "Saved: Robinson Chirinos\n",
      "Saved: Steve Cishek\n",
      "Saved: Alex Claudio\n",
      "Saved: Tyler Clippard\n",
      "Saved: Gerrit Cole\n",
      "Saved: C.J. Cron\n",
      "Saved: Travis d'Arnaud\n",
      "Saved: Corey Dickerson\n",
      "Saved: Jake Diekman\n",
      "Saved: Josh Donaldson\n",
      "Saved: Edwin Encarnacion\n",
      "Saved: Wilmer Flores\n",
      "Saved: Tyler Flowers\n",
      "Saved: Maikel Franco\n",
      "Saved: Todd Frazier\n",
      "Saved: Avisail Garcia\n",
      "Saved: Yimi Garcia\n",
      "Saved: Brett Gardner\n",
      "Saved: Kevin Gausman\n",
      "Saved: Kyle Gibson\n",
      "Saved: Gio Gonzalez\n",
      "Saved: Alex Gordon\n",
      "Saved: Yasmani Grandal\n",
      "Saved: Didi Gregorius\n",
      "Saved: Junior Guerra\n",
      "Saved: Jesse Hahn\n",
      "Saved: Cole Hamels\n",
      "Saved: Will Harris\n",
      "Saved: Adeiny Hechavarria\n",
      "Saved: Guillermo Heredia\n",
      "Saved: Cesar Hernandez\n",
      "Saved: Marco Hernandez\n",
      "Saved: Rich Hill\n",
      "Saved: Yoshihisa Hirano\n",
      "Saved: Brock Holt\n",
      "Saved: Daniel Hudson\n",
      "Saved: Tommy Hunter\n",
      "Saved: Jose Iglesias\n",
      "Already Exists: Jeremy Jeffress \n",
      "Already Exists: Matt Joyce \n",
      "Already Exists: Howie Kendrick \n",
      "Already Exists: Dallas Keuchel \n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "for year in range(min_year, max_year + 1):\n",
    "    print(\"PARSING YEAR\", year)\n",
    "    # Send a request to the ESPN page containing the data we need\n",
    "    response = requests.get('http://www.espn.com/mlb/freeagents/_/year/' + str(year))\n",
    "    content = response.content\n",
    "    print(\"Connection Status Code:\", response.status_code)\n",
    "\n",
    "    # Parse the HTML to find the table cells\n",
    "    parser = bs(content, 'html.parser')\n",
    "    table_rows = parser.find_all('tr', class_=['oddrow', 'evenrow'])\n",
    "    \n",
    "    # Save the data in a JSON file\n",
    "    for row in table_rows[:140]:\n",
    "        cells = row.select('td')\n",
    "\n",
    "        name = cells[0].text\n",
    "        year = year\n",
    "        pos = cells[1].text\n",
    "        status = cells[3].text\n",
    "        prev_team = cells[4].text\n",
    "        new_team = cells[5].text\n",
    "        years_signed = cells[6].text\n",
    "        dollars = cells[8].text\n",
    "                \n",
    "        # some players have no urls, so we will just skip them\n",
    "        try:\n",
    "            url = cells[0].select('a')[0]['href']\n",
    "        except IndexError:\n",
    "            continue\n",
    "            \n",
    "        # if a player has no age listed, we will also skip them\n",
    "        try:\n",
    "            age = int(cells[2].text) - (date.today().year - year)\n",
    "        except ValueError:\n",
    "            continue        \n",
    "            \n",
    "        # also skip players who did not sign a contract during their FA period\n",
    "        if years_signed == '':\n",
    "            continue\n",
    "        elif new_team == '--':\n",
    "            continue\n",
    "        elif dollars == '--' or dollars == 'Minor Lg':\n",
    "            continue\n",
    "            \n",
    "        # skip a  few players whose ESPN profiles are bugged / have no data\n",
    "        if name in ['José Molina','Brian Anderson','Hiroyuki Nakajima','Yaisel Sierra','Thomas Milone']:\n",
    "            continue\n",
    "        \n",
    "        # given a list of years and stats to find, retrieve the relevant data for that player\n",
    "        years = [year, year-1, year-2]\n",
    "        if pos == 'SP' or pos == 'RP' or pos== 'P':\n",
    "            stat_names = ['GP','GS','W','L','IP','K','BB','H','R','ER','SV','HLD','BLSV','WAR']\n",
    "        else:\n",
    "            stat_names = ['GP','AB','R','H','2B','3B','HR','RBI','BB','HBP','SO','SB','CS','WAR']\n",
    "        \n",
    "        stats = find_stats(url, years, stat_names)\n",
    "        save_to_json(name, year, url, pos, age, status, prev_team, new_team, years_signed, dollars, stat_names, stats)\n",
    "        \n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
